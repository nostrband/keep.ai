import { JSONSchema } from "../json-schema";
import { EvalContext } from "../sandbox/sandbox";
import { getEnv } from "../env";
import { getModelName } from "../model";
import debug from "debug";
import { AuthError, LogicError, NetworkError, InternalError, classifyHttpError, isClassifiedError, formatUsageForEvent } from "../errors";
import { defineTool, Tool } from "./types";

const debugTextGenerate = debug("TextGenerate");

const inputSchema: JSONSchema = {
  type: "object",
  properties: {
    prompt: {
      type: "string",
      minLength: 1,
      description: "Prompt to generate text from",
    },
    temperature: {
      type: "number",
      minimum: 0,
      maximum: 1,
      default: 0.3,
      description: "Sampling temperature: 0 is deterministic, 1 is very random (default: 0.3)",
    },
    max_chars: {
      type: "number",
      minimum: 100,
      maximum: 10000,
      default: 1500,
      description: "Maximum number of characters to generate (default: 1500)",
    },
  },
  required: ["prompt"],
};

const outputSchema: JSONSchema = {
  type: "object",
  properties: {
    text: { type: "string", description: "Generated text" },
  },
  required: ["text"],
};

interface Input {
  prompt: string;
  temperature?: number;
  max_chars?: number;
}

interface Output {
  text: string;
}

/**
 * Create the Text.generate tool.
 */
export function makeTextGenerateTool(getContext: () => EvalContext): Tool<Input, Output> {
  return defineTool({
    namespace: "Text",
    name: "generate",
    description: `Generate text based on a prompt using AI.
Takes a prompt and optional temperature/max_chars parameters, returns generated text.
Temperature controls randomness (0=deterministic, 1=very random), default 0.3.`,
    inputSchema,
    outputSchema,
    execute: async (input) => {
      const { prompt, temperature = 0.3, max_chars = 1500 } = input;

      const env = getEnv();
      if (!env.OPENROUTER_API_KEY?.trim()) {
        throw new AuthError("OpenRouter API key not configured", { source: "Text.generate" });
      }

      const model = getModelName();
      const baseURL = env.OPENROUTER_BASE_URL || "https://openrouter.ai/api/v1";

      debugTextGenerate(`Generating text with temperature ${temperature}, max ${max_chars} chars`);

      const systemPrompt = `You are a text generation assistant. Generate text based on the user's prompt.

If the prompt is malformed, unclear, inappropriate, or you cannot fulfill the request for any reason, provide brief reasoning and then output <ERROR>Short-error-text</ERROR> where Short-error-text explains the issue.`;

      try {
        const response = await fetch(`${baseURL}/chat/completions`, {
          method: "POST",
          headers: {
            Authorization: `Bearer ${env.OPENROUTER_API_KEY}`,
            "Content-Type": "application/json",
          },
          body: JSON.stringify({
            model,
            messages: [
              {
                role: "system",
                content: systemPrompt,
              },
              {
                role: "user",
                content: prompt,
              },
            ],
            temperature,
            max_tokens: Math.ceil(max_chars / 2), // Rough estimate: ~2 chars per token
            usage: {
              include: true,
            },
          }),
        });

        if (!response.ok) {
          const errorText = await response.text();
          throw classifyHttpError(
            response.status,
            `OpenRouter API error: ${response.status} - ${errorText}`,
            { source: "Text.generate" }
          );
        }

        const result = await response.json();

        if (!result.choices || result.choices.length === 0) {
          throw new NetworkError("No response generated by the model", { source: "Text.generate" });
        }

        const usage = result.usage || {};
        const content = result.choices[0].message?.content?.trim();
        if (!content) {
          throw new LogicError("No content found in the response", { source: "Text.generate" });
        }

        // Check for error pattern
        const errorMatch = content.match(/<ERROR>(.*?)<\/ERROR>/s);
        if (errorMatch) {
          const errorMessage = errorMatch[1].trim();
          throw new LogicError(errorMessage || "LLM reported an error", { source: "Text.generate" });
        }

        debugTextGenerate("Generation completed", {
          promptLength: prompt.length,
          generatedLength: content.length
        }, "usage", usage);

        await getContext().createEvent("text_generate", {
          promptLength: prompt.length,
          generatedLength: content.length,
          temperature,
          maxChars: max_chars,
          ...formatUsageForEvent(usage),
        });

        return { text: content };
      } catch (error) {
        // Re-throw if already classified
        if (isClassifiedError(error)) {
          throw error;
        }
        throw new InternalError(error instanceof Error ? error.message : String(error), { cause: error instanceof Error ? error : undefined, source: "Text.generate" });
      }
    },
  }) as Tool<Input, Output>;
}
